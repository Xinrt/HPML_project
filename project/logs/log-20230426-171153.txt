04/26/2023 17:11:53 - INFO - train -   Training in distributed mode with multiple processes, 1 device per process.Process 1, total 2, device cuda:1.
04/26/2023 17:11:53 - INFO - train -   Training in distributed mode with multiple processes, 1 device per process.Process 0, total 2, device cuda:0.
04/26/2023 17:12:01 - INFO - train -   Model resnet34 created, param count:33651792
04/26/2023 17:12:31 - INFO - train -   Using native Torch AMP. Training in mixed precision.
04/26/2023 17:12:31 - INFO - train -   Using native Torch DistributedDataParallel.
04/26/2023 17:12:44 - INFO - train -   Scheduled epochs: 3. LR stepped per epoch.
04/26/2023 17:12:55 - INFO - train -   Train: 0 [   0/105 (  0%)]  Loss: 7.074 (7.07)  Time: 11.001s,   23.27/s  (11.001s,   23.27/s)  LR: 5.500e-06  Data: 1.247 (1.247)
04/26/2023 17:13:07 - INFO - train -   Train: 0 [  50/105 ( 48%)]  Loss: 6.869 (6.97)  Time: 0.252s, 1014.57/s  (0.464s,  552.03/s)  LR: 5.500e-06  Data: 0.011 (0.037)
04/26/2023 17:13:21 - INFO - train -   Train: 0 [ 100/105 ( 96%)]  Loss: 6.915 (6.95)  Time: 0.261s,  979.05/s  (0.367s,  697.47/s)  LR: 5.500e-06  Data: 0.012 (0.032)
04/26/2023 17:13:22 - INFO - train -   Train: 0 [ 104/105 (100%)]  Loss: 6.912 (6.94)  Time: 0.228s, 1121.68/s  (0.362s,  706.96/s)  LR: 5.500e-06  Data: 0.000 (0.031)
04/26/2023 17:13:22 - INFO - train -   Distributing BatchNorm running means and vars
04/26/2023 17:13:29 - INFO - train -   Train: 1 [   0/105 (  0%)]  Loss: 6.894 (6.89)  Time: 5.137s,   49.83/s  (5.137s,   49.83/s)  LR: 5.504e-03  Data: 4.881 (4.881)
04/26/2023 17:13:42 - INFO - train -   Train: 1 [  50/105 ( 48%)]  Loss: 4.118 (5.51)  Time: 0.248s, 1032.44/s  (0.349s,  732.64/s)  LR: 5.504e-03  Data: 0.012 (0.108)
04/26/2023 17:13:54 - INFO - train -   Train: 1 [ 100/105 ( 96%)]  Loss: 3.906 (4.97)  Time: 0.252s, 1017.40/s  (0.305s,  840.31/s)  LR: 5.504e-03  Data: 0.011 (0.064)
04/26/2023 17:13:55 - INFO - train -   Train: 1 [ 104/105 (100%)]  Loss: 4.005 (4.73)  Time: 0.241s, 1063.55/s  (0.302s,  846.61/s)  LR: 5.504e-03  Data: 0.000 (0.062)
04/26/2023 17:13:55 - INFO - train -   Distributing BatchNorm running means and vars
04/26/2023 17:13:58 - INFO - train -   Train: 2 [   0/105 (  0%)]  Loss: 3.780 (3.78)  Time: 1.067s,  239.95/s  (1.067s,  239.95/s)  LR: 1.100e-02  Data: 0.820 (0.820)
04/26/2023 17:14:11 - INFO - train -   Train: 2 [  50/105 ( 48%)]  Loss: 3.607 (3.69)  Time: 0.262s,  975.78/s  (0.271s,  945.44/s)  LR: 1.100e-02  Data: 0.012 (0.029)
04/26/2023 17:14:23 - INFO - train -   Train: 2 [ 100/105 ( 96%)]  Loss: 3.299 (3.56)  Time: 0.262s,  975.37/s  (0.261s,  982.11/s)  LR: 1.100e-02  Data: 0.012 (0.021)
04/26/2023 17:14:24 - INFO - train -   Train: 2 [ 104/105 (100%)]  Loss: 3.483 (3.54)  Time: 0.242s, 1058.35/s  (0.260s,  983.22/s)  LR: 1.100e-02  Data: 0.000 (0.020)
04/26/2023 17:14:24 - INFO - train -   Distributing BatchNorm running means and vars
04/26/2023 17:14:24 - INFO - train -   ------------- Evaluting stitch config 0/10 -------------
04/26/2023 17:14:26 - INFO - train -   ------------- Evaluting stitch config 0/10 -------------
04/26/2023 17:14:27 - INFO - train -   Test: [   0/39]  Time: 1.170 (1.170)  Loss:  2.4629 (2.4629)  Acc@1: 42.1875 (42.1875)  Acc@5: 87.1094 (87.1094)
04/26/2023 17:14:30 - INFO - train -   Test: [  39/39]  Time: 0.063 (0.088)  Loss:  3.6543 (2.3093)  Acc@1: 31.2500 (45.6900)  Acc@5: 68.7500 (86.5000)
04/26/2023 17:14:30 - INFO - train -   ------------- Evaluting stitch config 1/10 -------------
04/26/2023 17:14:30 - INFO - train -   ------------- Evaluting stitch config 1/10 -------------
04/26/2023 17:14:31 - INFO - train -   Test: [   0/39]  Time: 0.663 (0.663)  Loss:  0.7861 (0.7861)  Acc@1: 90.6250 (90.6250)  Acc@5: 100.0000 (100.0000)
04/26/2023 17:14:33 - INFO - train -   ------------- Evaluting stitch config 2/10 -------------
04/26/2023 17:14:33 - INFO - train -   Test: [  39/39]  Time: 0.010 (0.070)  Loss:  0.8022 (0.7810)  Acc@1: 93.7500 (89.3300)  Acc@5: 100.0000 (100.0000)
04/26/2023 17:14:33 - INFO - train -   ------------- Evaluting stitch config 2/10 -------------
04/26/2023 17:14:33 - INFO - train -   Test: [   0/39]  Time: 0.586 (0.586)  Loss:  1.0557 (1.0557)  Acc@1: 78.5156 (78.5156)  Acc@5: 100.0000 (100.0000)
04/26/2023 17:14:40 - INFO - train -   ------------- Evaluting stitch config 3/10 -------------
04/26/2023 17:14:40 - INFO - train -   Test: [  39/39]  Time: 0.017 (0.169)  Loss:  1.1953 (1.0002)  Acc@1: 68.7500 (80.0600)  Acc@5: 100.0000 (99.9600)
04/26/2023 17:14:40 - INFO - train -   ------------- Evaluting stitch config 3/10 -------------
04/26/2023 17:14:40 - INFO - train -   Test: [   0/39]  Time: 0.678 (0.678)  Loss:  0.9717 (0.9717)  Acc@1: 82.8125 (82.8125)  Acc@5: 100.0000 (100.0000)
04/26/2023 17:14:42 - INFO - train -   ------------- Evaluting stitch config 4/10 -------------
04/26/2023 17:14:42 - INFO - train -   Test: [  39/39]  Time: 0.009 (0.065)  Loss:  1.5771 (0.9285)  Acc@1: 50.0000 (81.8200)  Acc@5: 100.0000 (99.9600)
04/26/2023 17:14:42 - INFO - train -   ------------- Evaluting stitch config 4/10 -------------
04/26/2023 17:14:43 - INFO - train -   Test: [   0/39]  Time: 0.599 (0.599)  Loss:  1.0654 (1.0654)  Acc@1: 75.3906 (75.3906)  Acc@5: 100.0000 (100.0000)
04/26/2023 17:14:45 - INFO - train -   Test: [  39/39]  Time: 0.009 (0.063)  Loss:  1.4209 (1.1089)  Acc@1: 75.0000 (75.1400)  Acc@5: 100.0000 (99.8700)
04/26/2023 17:14:45 - INFO - train -   ------------- Evaluting stitch config 5/10 -------------
04/26/2023 17:14:45 - INFO - train -   ------------- Evaluting stitch config 5/10 -------------
04/26/2023 17:14:46 - INFO - train -   Test: [   0/39]  Time: 0.623 (0.623)  Loss:  1.0635 (1.0635)  Acc@1: 87.1094 (87.1094)  Acc@5: 100.0000 (100.0000)
04/26/2023 17:14:48 - INFO - train -   ------------- Evaluting stitch config 6/10 -------------
04/26/2023 17:14:48 - INFO - train -   Test: [  39/39]  Time: 0.015 (0.063)  Loss:  1.0293 (1.0638)  Acc@1: 75.0000 (87.0500)  Acc@5: 100.0000 (99.9700)
04/26/2023 17:14:48 - INFO - train -   ------------- Evaluting stitch config 6/10 -------------
04/26/2023 17:14:48 - INFO - train -   Test: [   0/39]  Time: 0.600 (0.600)  Loss:  1.3145 (1.3145)  Acc@1: 71.0938 (71.0938)  Acc@5: 99.6094 (99.6094)
04/26/2023 17:14:50 - INFO - train -   Test: [  39/39]  Time: 0.009 (0.062)  Loss:  1.7549 (1.2910)  Acc@1: 56.2500 (70.4000)  Acc@5: 100.0000 (99.8400)
04/26/2023 17:14:50 - INFO - train -   ------------- Evaluting stitch config 7/10 -------------
04/26/2023 17:14:50 - INFO - train -   ------------- Evaluting stitch config 7/10 -------------
04/26/2023 17:14:51 - INFO - train -   Test: [   0/39]  Time: 0.613 (0.613)  Loss:  1.2773 (1.2773)  Acc@1: 70.7031 (70.7031)  Acc@5: 100.0000 (100.0000)
04/26/2023 17:14:58 - INFO - train -   ------------- Evaluting stitch config 8/10 -------------
04/26/2023 17:14:58 - INFO - train -   Test: [  39/39]  Time: 0.009 (0.188)  Loss:  1.3730 (1.2384)  Acc@1: 62.5000 (73.8700)  Acc@5: 100.0000 (99.8100)
04/26/2023 17:14:58 - INFO - train -   ------------- Evaluting stitch config 8/10 -------------
04/26/2023 17:14:59 - INFO - train -   Test: [   0/39]  Time: 0.634 (0.634)  Loss:  1.4980 (1.4980)  Acc@1: 71.8750 (71.8750)  Acc@5: 99.2188 (99.2188)
04/26/2023 17:15:01 - INFO - train -   ------------- Evaluting stitch config 9/10 -------------
04/26/2023 17:15:01 - INFO - train -   Test: [  39/39]  Time: 0.009 (0.082)  Loss:  1.8828 (1.4414)  Acc@1: 56.2500 (73.8300)  Acc@5: 100.0000 (99.5300)
04/26/2023 17:15:01 - INFO - train -   ------------- Evaluting stitch config 9/10 -------------
04/26/2023 17:15:02 - INFO - train -   Test: [   0/39]  Time: 1.005 (1.005)  Loss:  1.5527 (1.5527)  Acc@1: 73.4375 (73.4375)  Acc@5: 99.6094 (99.6094)
04/26/2023 17:15:05 - INFO - train -   Test: [  39/39]  Time: 0.008 (0.097)  Loss:  2.1016 (1.6039)  Acc@1: 43.7500 (70.0800)  Acc@5: 100.0000 (99.6000)
