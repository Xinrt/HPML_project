04/26/2023 15:12:17 - INFO - train -   Training in distributed mode with multiple processes, 1 device per process.Process 1, total 2, device cuda:1.
04/26/2023 15:12:17 - INFO - train -   Training in distributed mode with multiple processes, 1 device per process.Process 0, total 2, device cuda:0.
04/26/2023 15:12:18 - INFO - train -   Model resnet50 created, param count:37904976
04/26/2023 15:12:29 - INFO - train -   Using native Torch AMP. Training in mixed precision.
04/26/2023 15:12:29 - INFO - train -   Using native Torch DistributedDataParallel.
04/26/2023 15:12:35 - INFO - train -   Scheduled epochs: 3. LR stepped per epoch.
04/26/2023 15:12:41 - INFO - train -   Train: 0 [   0/105 (  0%)]  Loss: 8.292 (8.29)  Time: 5.834s,   43.88/s  (5.834s,   43.88/s)  LR: 5.500e-06  Data: 1.435 (1.435)
04/26/2023 15:12:57 - INFO - train -   Train: 0 [  50/105 ( 48%)]  Loss: 8.011 (8.15)  Time: 0.303s,  845.87/s  (0.424s,  603.96/s)  LR: 5.500e-06  Data: 0.011 (0.040)
04/26/2023 15:13:11 - INFO - train -   Train: 0 [ 100/105 ( 96%)]  Loss: 8.066 (8.12)  Time: 0.346s,  739.94/s  (0.360s,  711.91/s)  LR: 5.500e-06  Data: 0.010 (0.026)
04/26/2023 15:13:13 - INFO - train -   Train: 0 [ 104/105 (100%)]  Loss: 7.868 (8.06)  Time: 0.256s,  999.67/s  (0.356s,  719.27/s)  LR: 5.500e-06  Data: 0.000 (0.025)
04/26/2023 15:13:13 - INFO - train -   Distributing BatchNorm running means and vars
04/26/2023 15:13:15 - INFO - train -   Train: 1 [   0/105 (  0%)]  Loss: 8.311 (8.31)  Time: 1.032s,  247.99/s  (1.032s,  247.99/s)  LR: 5.504e-03  Data: 0.750 (0.750)
04/26/2023 15:13:30 - INFO - train -   Train: 1 [  50/105 ( 48%)]  Loss: 5.556 (6.93)  Time: 0.294s,  872.18/s  (0.312s,  820.62/s)  LR: 5.504e-03  Data: 0.012 (0.026)
04/26/2023 15:13:45 - INFO - train -   Train: 1 [ 100/105 ( 96%)]  Loss: 4.644 (6.17)  Time: 0.293s,  872.36/s  (0.303s,  844.25/s)  LR: 5.504e-03  Data: 0.011 (0.019)
04/26/2023 15:13:46 - INFO - train -   Train: 1 [ 104/105 (100%)]  Loss: 4.729 (5.81)  Time: 0.287s,  893.36/s  (0.302s,  846.62/s)  LR: 5.504e-03  Data: 0.000 (0.018)
04/26/2023 15:13:46 - INFO - train -   Distributing BatchNorm running means and vars
04/26/2023 15:13:49 - INFO - train -   Train: 2 [   0/105 (  0%)]  Loss: 4.614 (4.61)  Time: 1.072s,  238.79/s  (1.072s,  238.79/s)  LR: 1.100e-02  Data: 0.781 (0.781)
04/26/2023 15:14:04 - INFO - train -   Train: 2 [  50/105 ( 48%)]  Loss: 4.467 (4.54)  Time: 0.352s,  726.65/s  (0.314s,  815.46/s)  LR: 1.100e-02  Data: 0.011 (0.027)
04/26/2023 15:14:18 - INFO - train -   Train: 2 [ 100/105 ( 96%)]  Loss: 4.341 (4.47)  Time: 0.352s,  726.27/s  (0.302s,  848.52/s)  LR: 1.100e-02  Data: 0.012 (0.019)
04/26/2023 15:14:20 - INFO - train -   Train: 2 [ 104/105 (100%)]  Loss: 4.285 (4.43)  Time: 0.289s,  885.10/s  (0.302s,  847.93/s)  LR: 1.100e-02  Data: 0.000 (0.019)
04/26/2023 15:14:20 - INFO - train -   Distributing BatchNorm running means and vars
04/26/2023 15:14:20 - INFO - train -   ------------- Evaluting stitch config 0/10 -------------
04/26/2023 15:14:21 - INFO - train -   ------------- Evaluting stitch config 0/10 -------------
04/26/2023 15:14:23 - INFO - train -   Test: [   0/39]  Time: 1.092 (1.092)  Loss:  2.1426 (2.1426)  Acc@1: 52.7344 (52.7344)  Acc@5: 87.1094 (87.1094)
04/26/2023 15:14:25 - INFO - train -   Test: [  39/39]  Time: 0.060 (0.076)  Loss:  3.1133 (1.9951)  Acc@1: 37.5000 (53.8800)  Acc@5: 75.0000 (89.7300)
04/26/2023 15:14:25 - INFO - train -   ------------- Evaluting stitch config 1/10 -------------
04/26/2023 15:14:25 - INFO - train -   ------------- Evaluting stitch config 1/10 -------------
04/26/2023 15:14:26 - INFO - train -   Test: [   0/39]  Time: 0.715 (0.715)  Loss:  5.6641 (5.6641)  Acc@1: 57.8125 (57.8125)  Acc@5: 92.1875 (92.1875)
04/26/2023 15:14:28 - INFO - train -   Test: [  39/39]  Time: 0.247 (0.084)  Loss:  2.2617 (3.7969)  Acc@1: 75.0000 (57.2500)  Acc@5: 100.0000 (93.4600)
04/26/2023 15:14:28 - INFO - train -   ------------- Evaluting stitch config 2/10 -------------
04/26/2023 15:14:28 - INFO - train -   ------------- Evaluting stitch config 2/10 -------------
04/26/2023 15:14:29 - INFO - train -   Test: [   0/39]  Time: 0.724 (0.724)  Loss:  1.0283 (1.0283)  Acc@1: 88.6719 (88.6719)  Acc@5: 100.0000 (100.0000)
04/26/2023 15:14:31 - INFO - train -   ------------- Evaluting stitch config 3/10 -------------
04/26/2023 15:14:31 - INFO - train -   Test: [  39/39]  Time: 0.011 (0.070)  Loss:  0.9717 (0.9775)  Acc@1: 93.7500 (88.2000)  Acc@5: 100.0000 (99.8700)
04/26/2023 15:14:31 - INFO - train -   ------------- Evaluting stitch config 3/10 -------------
04/26/2023 15:14:32 - INFO - train -   Test: [   0/39]  Time: 0.632 (0.632)  Loss:  0.8105 (0.8105)  Acc@1: 91.4062 (91.4062)  Acc@5: 100.0000 (100.0000)
04/26/2023 15:14:34 - INFO - train -   ------------- Evaluting stitch config 4/10 -------------
04/26/2023 15:14:34 - INFO - train -   Test: [  39/39]  Time: 0.012 (0.068)  Loss:  0.6401 (0.7799)  Acc@1: 93.7500 (92.3200)  Acc@5: 100.0000 (99.8600)
04/26/2023 15:14:34 - INFO - train -   ------------- Evaluting stitch config 4/10 -------------
04/26/2023 15:14:35 - INFO - train -   Test: [   0/39]  Time: 0.609 (0.609)  Loss:  1.4414 (1.4414)  Acc@1: 80.4688 (80.4688)  Acc@5: 99.6094 (99.6094)
04/26/2023 15:14:37 - INFO - train -   Test: [  39/39]  Time: 0.010 (0.066)  Loss:  1.2822 (1.3224)  Acc@1: 81.2500 (85.0800)  Acc@5: 100.0000 (99.7700)
04/26/2023 15:14:37 - INFO - train -   ------------- Evaluting stitch config 5/10 -------------
04/26/2023 15:14:37 - INFO - train -   ------------- Evaluting stitch config 5/10 -------------
04/26/2023 15:14:38 - INFO - train -   Test: [   0/39]  Time: 0.589 (0.589)  Loss:  1.9893 (1.9893)  Acc@1: 77.7344 (77.7344)  Acc@5: 100.0000 (100.0000)
04/26/2023 15:14:40 - INFO - train -   ------------- Evaluting stitch config 6/10 -------------
04/26/2023 15:14:40 - INFO - train -   Test: [  39/39]  Time: 0.011 (0.064)  Loss:  1.6504 (1.9789)  Acc@1: 81.2500 (76.6700)  Acc@5: 100.0000 (99.2100)
04/26/2023 15:14:40 - INFO - train -   ------------- Evaluting stitch config 6/10 -------------
04/26/2023 15:14:40 - INFO - train -   Test: [   0/39]  Time: 0.581 (0.581)  Loss:  2.2188 (2.2188)  Acc@1: 65.6250 (65.6250)  Acc@5: 97.6562 (97.6562)
04/26/2023 15:14:42 - INFO - train -   ------------- Evaluting stitch config 7/10 -------------
04/26/2023 15:14:42 - INFO - train -   Test: [  39/39]  Time: 0.011 (0.064)  Loss:  1.7773 (2.1906)  Acc@1: 87.5000 (65.3900)  Acc@5: 100.0000 (97.9700)
04/26/2023 15:14:42 - INFO - train -   ------------- Evaluting stitch config 7/10 -------------
04/26/2023 15:14:43 - INFO - train -   Test: [   0/39]  Time: 0.628 (0.628)  Loss:  1.8711 (1.8711)  Acc@1: 80.4688 (80.4688)  Acc@5: 98.8281 (98.8281)
04/26/2023 15:14:45 - INFO - train -   Test: [  39/39]  Time: 0.010 (0.066)  Loss:  1.8066 (1.9059)  Acc@1: 93.7500 (79.0300)  Acc@5: 100.0000 (98.4500)
04/26/2023 15:14:45 - INFO - train -   ------------- Evaluting stitch config 8/10 -------------
04/26/2023 15:14:45 - INFO - train -   ------------- Evaluting stitch config 8/10 -------------
04/26/2023 15:14:46 - INFO - train -   Test: [   0/39]  Time: 0.609 (0.609)  Loss:  2.1230 (2.1230)  Acc@1: 85.1562 (85.1562)  Acc@5: 99.2188 (99.2188)
04/26/2023 15:14:48 - INFO - train -   Test: [  39/39]  Time: 0.010 (0.063)  Loss:  2.0820 (2.1426)  Acc@1: 81.2500 (81.9200)  Acc@5: 100.0000 (98.2000)
04/26/2023 15:14:48 - INFO - train -   ------------- Evaluting stitch config 9/10 -------------
04/26/2023 15:14:48 - INFO - train -   ------------- Evaluting stitch config 9/10 -------------
04/26/2023 15:14:49 - INFO - train -   Test: [   0/39]  Time: 0.630 (0.630)  Loss:  2.2500 (2.2500)  Acc@1: 94.5312 (94.5312)  Acc@5: 100.0000 (100.0000)
04/26/2023 15:14:51 - INFO - train -   Test: [  39/39]  Time: 0.009 (0.062)  Loss:  2.2930 (2.2593)  Acc@1: 93.7500 (92.9000)  Acc@5: 100.0000 (99.4400)
